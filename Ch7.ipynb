{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a586fd03",
   "metadata": {},
   "source": [
    "# 7장 새와 비행기 구별하기: 이미지 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d01f4",
   "metadata": {},
   "source": [
    "고전 데이터셋인 CIFAR-10을 토치비전에서 다운로드할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf2f213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (0.13.1)\n",
      "Requirement already satisfied: torch==1.12.1 in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (1.12.1)\n",
      "Requirement already satisfied: requests in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from torchvision) (4.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from requests->torchvision) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from requests->torchvision) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\.conda\\envs\\ml\\lib\\site-packages (from requests->torchvision) (3.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe21dbf",
   "metadata": {},
   "source": [
    "## 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61af24ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\.conda\\envs\\ml\\lib\\site-packages\\torch\\random.py:42: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
      "  return default_generator.manual_seed(seed)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x28563d48cf0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_printoptions(edgeitems=2, linewidth=75)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b046711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "cifar10 = datasets.CIFAR10(data_path, train=True, download=True) # <1>\n",
    "cifar10_val = datasets.CIFAR10(data_path, train=False, download=True) # <2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be232c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_names = ['airplane','automobile','bird','cat','deer',\n",
    "               'dog','frog','horse','ship','truck']\n",
    "\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "num_classes = 10\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    ax.set_title(class_names[i])\n",
    "    img = next(img for img, label in cifar10 if label == i)\n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84dff68",
   "metadata": {},
   "source": [
    "CIFAR-10은 torch.utils.data.Dataset의 서브클래스이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c65f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "type(cifar10).__mro__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f6701",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(cifar10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd821f7",
   "metadata": {},
   "source": [
    "CIFAR은 RGB로 이루어진 이미지이고, 다음은 자동차에 해당하는 정수값이 1인 PIL 형식의 이미지를 얻는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = cifar10[99]\n",
    "img, label, class_names[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee15d9b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097ff1e4",
   "metadata": {},
   "source": [
    "이미지를 텐서로 변환하려면 torchvision의 transforms를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a396ef5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "dir(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701026ec",
   "metadata": {},
   "source": [
    "이중에서 transforms.ToTensor를 사용하면 텐서로 만들어줌과 동시에 CxHxW 형식의 텐서로 변환해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ce6d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306b7838",
   "metadata": {},
   "source": [
    "변환 자체를 dataset.CIFAR10의 인자로 전달하는 것도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a00ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_cifar10 = datasets.CIFAR10(data_path, train=True, download=False,\n",
    "                          transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac417cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t, _ = tensor_cifar10[99]\n",
    "type(img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc68e1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t.shape, img_t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d383702",
   "metadata": {},
   "source": [
    "ToTensor() 변환으로 원래 0부터 255의 범위였던 이미지 값이 0.0부터 1.0 사이로 범위가 줄어든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f978",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t.min(), img_t.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44677de1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_t.permute(1, 2, 0))  # <1>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f322e2",
   "metadata": {},
   "source": [
    "모든 채널이 평균값 0과 단위 표준편차를 가지기 위해 연산을 해줘야 하는데, 먼저 데이터셋이 반환하는 모든 텐서를 쌓아놓는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7503a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = torch.stack([img_t for img_t, _ in tensor_cifar10], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87ea034",
   "metadata": {},
   "source": [
    "이제 view()함수를 통해 (3, 32, 32)였던 이미지를 (3, 1024)로 변환해준 후 평균과 표준편차를 구한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6dfb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.view(3, -1).mean(dim=1)  # <1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eb6d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1723f9",
   "metadata": {},
   "source": [
    "이제 평균과 표준편차로 Normalize 변환을 초기화할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a404bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms.Normalize((0.4915, 0.4823, 0.4468), (0.2470, 0.2435, 0.2616))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2681b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a941af96",
   "metadata": {},
   "source": [
    "이제 Compose를 할 때 여러 변환과 동시에 정규화도 해줄 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4b4281",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_cifar10_val = datasets.CIFAR10(\n",
    "    data_path, train=False, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dc48c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_t, _ = transformed_cifar10[99]\n",
    "\n",
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978cec6",
   "metadata": {},
   "source": [
    "## 새와 비행기를 구별하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d484c04",
   "metadata": {},
   "source": [
    "먼저 데이터의 차원 정보를 맞춰야 한다, 굳이 Dataset의 서브클래스일 필요는 없으므로, __len__과 __getitem__이 정의되어 있으면 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2584213",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {0: 0, 2: 1}\n",
    "class_names = ['airplane', 'bird']\n",
    "cifar2 = [(img, label_map[label])\n",
    "          for img, label in cifar10 \n",
    "          if label in [0, 2]]\n",
    "cifar2_val = [(img, label_map[label])\n",
    "              for img, label in cifar10_val\n",
    "              if label in [0, 2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b66e5a",
   "metadata": {},
   "source": [
    "이미지를 1차원 벡터로 간주하여 완전 연결 분류기를 만들수 있다. 피처는 3*32*32해서 3072개이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd1069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_out = 2\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                3072,  # <1>\n",
    "                512,   # <2>\n",
    "            ),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(\n",
    "                512,   # <2>\n",
    "                n_out, # <3>\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b15c7",
   "metadata": {},
   "source": [
    "이미지가 새인지, 비행기인지 분류하는 문제이므로 타겟 데이터를 원핫 벡터로 만들어줘야 한다. 또 한가지 새로운 사실은 각 인덱스에 대한 값을 확률로 표현할 수 있다는 점이다. 이렇게 모든 출력 요소의 합이 1이고 요소가 가질 수 있는 값이 0.0에서 1.0 사이로 만드는 함수가 소프트맥스 함수이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ee71fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return torch.exp(x) / torch.exp(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9f7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba4f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax(x).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7d9a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[1.0, 2.0, 3.0],\n",
    "                  [1.0, 2.0, 3.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d495f810",
   "metadata": {},
   "source": [
    "이제 nn.Sequential로 모델을 완성해볼 수 있다. 이미지를 하나 골라서 확률을 구해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01763ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.Softmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6cab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = cifar2[0]\n",
    "\n",
    "plt.imshow(img.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152821a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch = img.view(-1).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772374e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = model(img_batch)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1c6353",
   "metadata": {},
   "source": [
    "예측 벡터에서 뭐가 무슨 레이블인지 명시되어 있지 않다. 이를 위해 argmax로 값이 가장 큰 인덱스를 반환하는 함수를 쓸 수 있다. torch.max는 인자로 받은 차원에서 가장 값이 높은 인덱스를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc517a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, index = torch.max(out, dim=1)\n",
    "\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86993dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.tensor([\n",
    "    [0.6, 0.4],\n",
    "    [0.9, 0.1],\n",
    "    [0.3, 0.7],\n",
    "    [0.2, 0.8],\n",
    "])\n",
    "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
    "\n",
    "truth = torch.zeros((4,2))\n",
    "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
    "truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3892cbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(out):\n",
    "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
    "mse(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47ed172",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.gather(dim=1, index=class_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8849a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(out):\n",
    "    prod = 1.0\n",
    "    for x in out.gather(dim=1, index=class_index):\n",
    "        prod *= x\n",
    "    return prod\n",
    "\n",
    "likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaa2000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(out):\n",
    "    return -likelihood(out).log()\n",
    "\n",
    "neg_log_likelihood(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765bac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "out0 = out.clone().detach()\n",
    "out0[0] = torch.tensor([0.9, 0.1]) # more right\n",
    "\n",
    "out2 = out.clone().detach()\n",
    "out2[0] = torch.tensor([0.4, 0.6]) # slightly wrong\n",
    "\n",
    "out3 = out.clone().detach()\n",
    "out3[0] = torch.tensor([0.1, 0.9]) # very wrong\n",
    "\n",
    "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
    "mse_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07c53f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "((mse_comparison / mse_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_comparison = torch.tensor([neg_log_likelihood(o) \n",
    "                               for o in [out0, out, out2, out3]])\n",
    "nll_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf32a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "((nll_comparison / nll_comparison[1]) - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec713a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb32b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "\n",
    "log_softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "x = torch.tensor([[0.0, 104.0]])\n",
    "\n",
    "softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.log(softmax(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd19235",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(log_softmax(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb15bcb",
   "metadata": {},
   "source": [
    "이런 분류 문제에서는 단순히 손실값을 줄이는 것이 목표가 아니라, 가능도가 높고 다른 타겟 인덱스에 대한 확률이 낮아야 한다. 이러한 지표를 가르키는 함수 중에는 nn.NLLLoss가 있다. 이 손실 함수는 입력을 확률 대신 로그 확률의 텐서를 받는다. 이를 위해 마지막에 nn.LogSoftmax 함수로 반환해주자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d42d83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f524ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = cifar2[0]\n",
    "\n",
    "out = model(img.view(-1).unsqueeze(0))\n",
    "\n",
    "loss(out, torch.tensor([label]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c78c73",
   "metadata": {},
   "source": [
    "이제 본격적으로 훈련해 볼 수 있다. 단일 배치에 1만개의 이미지를 모두 평가하는 것은 너무 많으므로 내부 루프 안에 한번의 하나의 샘플을 평가하고 단일 샘플에 대해 역전파해 볼 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4f5f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for img, label in cifar2:\n",
    "        out = model(img.view(-1).unsqueeze(0))\n",
    "        loss = loss_fn(out, torch.tensor([label]))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62114131",
   "metadata": {},
   "source": [
    "우리는 한번에 하나의 아이템을 골라 크기가 1인 미니 배치를 만드는데, DataLoader 클래스를 통해 배치 사이즈와 랜덤 샘플링을 할 shuffle=True를 사용하여 인덱스를 섞을 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01eebd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cecf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 2),\n",
    "            nn.LogSoftmax(dim=1))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.NLLLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a47428",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7016fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64,\n",
    "                                         shuffle=False)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in val_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += int((predicted == labels).sum())\n",
    "        \n",
    "print(\"Accuracy: %f\" % (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b442e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2),\n",
    "            nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0100c9e",
   "metadata": {},
   "source": [
    "사실 nn.LogSoftmax와 nn.NLLLoss는 CrossEntropyLoss()와 같다. 대부분의 경우 Softmax를 하지 않고 마지막에 nn.CrossEntropyLoss를 사용할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4072ca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae10dfe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(3072, 1024),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 2))\n",
    "\n",
    "learning_rate = 1e-2\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for imgs, labels in train_loader:\n",
    "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c215cf0",
   "metadata": {},
   "source": [
    "## 연습문제\n",
    "1. torchvision을 사용하여 데이터를 임의로 잘라내보자\\\n",
    "a.원래의 이미지와 비교하여 어떤 점이 다른가?\\\n",
    "b. 동일한 이미지를 다시 처리하면 어떻게 되는가?\\\n",
    "c. 랜덤하게 크롭된 이미지로 훈련시킨 결과는 어떠한가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1904bac7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "data_path = '../data-unversioned/p1ch7/'\n",
    "transformed_cifar10 = datasets.CIFAR10(\n",
    "    data_path, train=True, download=False,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
    "                             (0.2470, 0.2435, 0.2616))\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b601dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6178ca53",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CIFAR10' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\AI Tech\\dlwpt-code-master\\Ch7.ipynb 셀 86\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danie/AI%20Tech/dlwpt-code-master/Ch7.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m transformed_cifar10\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CIFAR10' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "transformed_cifar10.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d326c070",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\danie\\AI Tech\\dlwpt-code-master\\Ch7.ipynb 셀 87\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/AI%20Tech/dlwpt-code-master/Ch7.ipynb#Y152sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/danie/AI%20Tech/dlwpt-code-master/Ch7.ipynb#Y152sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m img, _ \u001b[39m=\u001b[39m cifar10[\u001b[39m99\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/AI%20Tech/dlwpt-code-master/Ch7.ipynb#Y152sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m n_img \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mcrop(img, \u001b[39m50\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m50\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/danie/AI%20Tech/dlwpt-code-master/Ch7.ipynb#Y152sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m n_img\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cifar10' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "img, _ = cifar10[99]\n",
    "n_img = transforms.functional.crop(img, 50, 50, 50, 50)\n",
    "n_img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7953c2e2f0e0f8197bd70324d9c1633d9554722d040732679f1b95d78e4566cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
